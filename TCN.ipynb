{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 02s]\n",
      "\n",
      "Best val_loss So Far: None\n",
      "Total elapsed time: 00h 00m 03s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "6                 |3                 |dilation_depth\n",
      "256               |224               |nb_filters\n",
      "5                 |7                 |kernel_size\n",
      "3                 |2                 |nb_stacks\n",
      "False             |False             |use_skip_connections\n",
      "0.3               |0.3               |dropout_rate\n",
      "relu              |relu              |activation\n",
      "True              |False             |use_batch_norm\n",
      "False             |False             |use_layer_norm\n",
      "64                |16                |dense_units\n",
      "selu              |relu              |dense_activation\n",
      "adam              |sgd               |optimizer\n",
      "0.0068984         |0.00012798        |learning_rate\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\matth\\AppData\\Local\\Temp\\__autograph_generated_filehqa2srij.py\", line 18, in tf__train_function\n",
      "    raise\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n",
      "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n",
      "        return self.compiled_loss(\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 1470, in mean_squared_error\n",
      "        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n",
      "\n",
      "    ValueError: Dimensions must be equal, but are 64 and 7 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/dense/Selu, IteratorGetNext:1)' with input shapes: [?,64], [?,7].\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\matth\\AppData\\Local\\Temp\\__autograph_generated_filehqa2srij.py\", line 18, in tf__train_function\n    raise\nValueError: in user code:\n\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 1470, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 64 and 7 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/dense/Selu, IteratorGetNext:1)' with input shapes: [?,64], [?,7].\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 119\u001b[0m\n\u001b[0;32m    109\u001b[0m tuner \u001b[38;5;241m=\u001b[39m RandomSearch(\n\u001b[0;32m    110\u001b[0m     build_tcn_model,\n\u001b[0;32m    111\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy_forecasting_tcn\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Run hyperparameter search\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[0;32m    128\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:339\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[0;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[1;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[0;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:588\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:545\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    543\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    549\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\matth\\AppData\\Local\\Temp\\__autograph_generated_filehqa2srij.py\", line 18, in tf__train_function\n    raise\nValueError: in user code:\n\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\matth\\anaconda3\\envs\\AISE4010\\Lib\\site-packages\\keras\\losses.py\", line 1470, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 64 and 7 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/dense/Selu, IteratorGetNext:1)' with input shapes: [?,64], [?,7].\n\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tcn import TCN\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# ------------------ Utility Functions ------------------ #\n",
    "def load_and_preprocess_data(filepath):\n",
    "    \"\"\"Load and preprocess the dataset.\"\"\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    df_grouped = data.groupby(['date', 'generation_type'], as_index=False)['megawatt_hours'].sum()\n",
    "    return df_grouped\n",
    "\n",
    "def standardize_generation_types(df, unique_types):\n",
    "    \"\"\"Ensure all generation types are represented for every date.\"\"\"\n",
    "    all_dates = df['date'].unique()\n",
    "    standardized_rows = [\n",
    "        {'date': date, 'generation_type': g_type, 'megawatt_hours': 0}\n",
    "        for date in all_dates\n",
    "        for g_type in unique_types\n",
    "        if g_type not in df[df['date'] == date]['generation_type'].values\n",
    "    ]\n",
    "    return pd.concat([df, pd.DataFrame(standardized_rows)], ignore_index=True)\n",
    "\n",
    "def scale_data(df):\n",
    "    \"\"\"Scale the data using MinMaxScaler.\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    return scaled_data, scaler\n",
    "\n",
    "def create_sequences(data, n_steps):\n",
    "    \"\"\"Create input-output sequences for time-series data.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps):\n",
    "        X.append(data[i:i + n_steps])\n",
    "        y.append(data[i + n_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ------------------ Model Building Function ------------------ #\n",
    "def build_tcn_model(hp):\n",
    "    \"\"\"Build the TCN model with hyperparameters.\"\"\"\n",
    "    dilation_depth = hp.Int('dilation_depth', min_value=2, max_value=6, step=1)\n",
    "    dilations = [2**i for i in range(dilation_depth)]\n",
    "    \n",
    "    model = Sequential([\n",
    "        Input(shape=(n_steps, X_train.shape[2])),\n",
    "        TCN(\n",
    "            nb_filters=hp.Int('nb_filters', min_value=32, max_value=256, step=32),\n",
    "            kernel_size=hp.Choice('kernel_size', values=[2, 3, 5, 7]),\n",
    "            nb_stacks=hp.Int('nb_stacks', min_value=1, max_value=3),\n",
    "            dilations=dilations,\n",
    "            padding='causal',  # Use causal padding to prevent data leakage\n",
    "            use_skip_connections=hp.Boolean('use_skip_connections'),\n",
    "            dropout_rate=hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1),\n",
    "            activation=hp.Choice('activation', values=['relu', 'tanh', 'selu', 'gelu']),\n",
    "            use_batch_norm=hp.Boolean('use_batch_norm'),\n",
    "            use_layer_norm=hp.Boolean('use_layer_norm'),\n",
    "        ),\n",
    "        Dense(\n",
    "    units=X_train.shape[2],  # Match the output shape to the target\n",
    "    activation=hp.Choice('dense_activation', values=['relu', 'tanh', 'selu'])\n",
    ")\n",
    "    ])\n",
    "    \n",
    "    optimizer = hp.Choice('optimizer', values=['adam', 'rmsprop', 'sgd'])\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    if optimizer == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae', 'mape']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ------------------ Main Script ------------------ #\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    filepath = r'data/processed/canada_energy.csv'\n",
    "    df_grouped = load_and_preprocess_data(filepath)\n",
    "    unique_generation_types = df_grouped['generation_type'].unique()\n",
    "    df_standardized = standardize_generation_types(df_grouped, unique_generation_types)\n",
    "    df_pivot = df_standardized.pivot(index='date', columns='generation_type', values='megawatt_hours').fillna(0)\n",
    "    df_pivot[df_pivot < 0] = 0\n",
    "\n",
    "    # Scale data\n",
    "    data_scaled, scaler = scale_data(df_pivot)\n",
    "\n",
    "    # Define time steps and create sequences\n",
    "    n_steps = 36\n",
    "    X, y = create_sequences(data_scaled, n_steps)\n",
    "    test_size = 24  # Assuming 24 months (2 years) for testing\n",
    "    train_data, test_data = data_scaled[:-test_size], data_scaled[-test_size - n_steps:]\n",
    "    X_train, y_train = create_sequences(train_data, n_steps)\n",
    "    X_test, y_test = create_sequences(test_data, n_steps)\n",
    "\n",
    "    # Set up hyperparameter tuning\n",
    "    tuner = RandomSearch(\n",
    "        build_tcn_model,\n",
    "        objective='val_loss',\n",
    "        max_trials=50,\n",
    "        executions_per_trial=2,\n",
    "        directory='tcn_hyperparam_search',\n",
    "        project_name='energy_forecasting_tcn'\n",
    "    )\n",
    "\n",
    "    # Run hyperparameter search\n",
    "    tuner.search(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        validation_data=(X_test, y_test),\n",
    "        batch_size=32,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    # Print optimal hyperparameters\n",
    "    print(f\"\"\"\n",
    "    Optimal hyperparameters:\n",
    "    - Filters: {best_hps.get('nb_filters')}\n",
    "    - Kernel size: {best_hps.get('kernel_size')}\n",
    "    - Stacks: {best_hps.get('nb_stacks')}\n",
    "    - Dilation depth: {best_hps.get('dilation_depth')}\n",
    "    - Dropout rate: {best_hps.get('dropout_rate')}\n",
    "    - Activation: {best_hps.get('activation')}\n",
    "    - Batch normalization: {best_hps.get('use_batch_norm')}\n",
    "    - Layer normalization: {best_hps.get('use_layer_norm')}\n",
    "    - Dense units: {best_hps.get('dense_units')}\n",
    "    - Dense activation: {best_hps.get('dense_activation')}\n",
    "    - Optimizer: {best_hps.get('optimizer')}\n",
    "    - Learning rate: {best_hps.get('learning_rate')}\n",
    "    \"\"\")\n",
    "\n",
    "    # Retrain the model with the best hyperparameters\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "    history = best_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dilation_depth': 6, 'nb_filters': 80, 'kernel_size': 3, 'nb_stacks': 1, 'use_skip_connections': False, 'dropout_rate': 0.0, 'activation': 'tanh', 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#print the best hyperparameters\n",
    "print(tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AISE4010",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
